{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY7k7BsEscPg",
        "outputId": "677447ec-2cd5-422b-d4ad-6493f88cabe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to Tic Tac Toe!\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "Enter row (0, 1, or 2): 0\n",
            "Enter column (0, 1, or 2): 1\n",
            "[[0 1 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "[[-1  1  0]\n",
            " [ 0  0  0]\n",
            " [ 0  0  0]]\n",
            "Enter row (0, 1, or 2): 3\n",
            "Enter column (0, 1, or 2): 2\n",
            "Invalid move. Try again.\n",
            "Enter row (0, 1, or 2): 1\n",
            "Enter column (0, 1, or 2): 2\n",
            "[[-1  1  0]\n",
            " [ 0  0  1]\n",
            " [ 0  0  0]]\n",
            "[[-1  1 -1]\n",
            " [ 0  0  1]\n",
            " [ 0  0  0]]\n",
            "Enter row (0, 1, or 2): 2\n",
            "Enter column (0, 1, or 2): 1\n",
            "[[-1  1 -1]\n",
            " [ 0  0  1]\n",
            " [ 0  1  0]]\n",
            "[[-1  1 -1]\n",
            " [-1  0  1]\n",
            " [ 0  1  0]]\n",
            "Enter row (0, 1, or 2): 1\n",
            "Enter column (0, 1, or 2): 1\n",
            "[[-1  1 -1]\n",
            " [-1  1  1]\n",
            " [ 0  1  0]]\n",
            "You win!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "ROWS, COLS = 3, 3\n",
        "EMPTY, PLAYER_X, PLAYER_O = 0, 1, -1\n",
        "WIN_REWARD = 1\n",
        "DRAW_REWARD = 0\n",
        "LOSE_REWARD = -1\n",
        "LEARNING_RATE = 0.1\n",
        "DISCOUNT_FACTOR = 0.9\n",
        "EXPLORATION_PROB = 0.1\n",
        "\n",
        "# Initialize Q-table using a dictionary\n",
        "q_table = {}\n",
        "\n",
        "def initialize_board():\n",
        "    return np.zeros((ROWS, COLS), dtype=int)\n",
        "\n",
        "def get_board_hash(board):\n",
        "    return board.tobytes()\n",
        "\n",
        "def get_legal_moves(board):\n",
        "    return list(zip(*np.where(board == EMPTY)))\n",
        "\n",
        "def make_move(board, player, row, col):\n",
        "    board[row, col] = player\n",
        "\n",
        "def check_winner(board):\n",
        "    # Check rows and columns\n",
        "    if np.any(np.abs(np.sum(board, axis=0)) == ROWS) or np.any(np.abs(np.sum(board, axis=1)) == COLS):\n",
        "        return True\n",
        "\n",
        "    # Check diagonals\n",
        "    if np.abs(np.trace(board)) == ROWS or np.abs(np.trace(np.fliplr(board))) == ROWS:\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def get_reward(board):\n",
        "    if check_winner(board):\n",
        "        return WIN_REWARD\n",
        "    elif np.all(board != EMPTY):\n",
        "        return DRAW_REWARD\n",
        "    else:\n",
        "        return LOSE_REWARD\n",
        "\n",
        "def get_best_move(board, player):\n",
        "    legal_moves = get_legal_moves(board)\n",
        "\n",
        "    if random.uniform(0, 1) < EXPLORATION_PROB:\n",
        "        return random.choice(legal_moves)\n",
        "\n",
        "    best_move = None\n",
        "    best_value = -float('inf') if player == PLAYER_X else float('inf')\n",
        "\n",
        "    for move in legal_moves:\n",
        "        next_board = board.copy()\n",
        "        make_move(next_board, player, *move)\n",
        "        next_board_hash = get_board_hash(next_board)\n",
        "        q_value = q_table.get((next_board_hash, player), 0)\n",
        "\n",
        "        if player == PLAYER_X:\n",
        "            if q_value > best_value:\n",
        "                best_value = q_value\n",
        "                best_move = move\n",
        "        else:\n",
        "            if q_value < best_value:\n",
        "                best_value = q_value\n",
        "                best_move = move\n",
        "\n",
        "    return best_move\n",
        "\n",
        "def train_q_learning(episodes=50000):\n",
        "    for _ in range(episodes):\n",
        "        current_board = initialize_board()\n",
        "        current_player = PLAYER_X\n",
        "\n",
        "        while True:\n",
        "            current_board_hash = get_board_hash(current_board)\n",
        "            legal_moves = get_legal_moves(current_board)\n",
        "\n",
        "            # Choose action\n",
        "            if random.uniform(0, 1) < EXPLORATION_PROB:\n",
        "                action = random.choice(legal_moves)\n",
        "            else:\n",
        "                action = get_best_move(current_board, current_player)\n",
        "\n",
        "            # Take action\n",
        "            make_move(current_board, current_player, *action)\n",
        "\n",
        "            # Check for game end\n",
        "            if check_winner(current_board) or np.all(current_board != EMPTY):\n",
        "                reward = get_reward(current_board)\n",
        "                q_value = q_table.get((current_board_hash, current_player), 0)\n",
        "\n",
        "                # Update Q-value\n",
        "                updated_q_value = (1 - LEARNING_RATE) * q_value + LEARNING_RATE * (reward + DISCOUNT_FACTOR * max(q_table.get((get_board_hash(current_board), PLAYER_X), 0),\n",
        "                                                                                                               q_table.get((get_board_hash(current_board), PLAYER_O), 0)))\n",
        "                q_table[(current_board_hash, current_player)] = updated_q_value\n",
        "                break\n",
        "\n",
        "            # Switch player\n",
        "            current_player = PLAYER_X if current_player == PLAYER_O else PLAYER_O\n",
        "\n",
        "# Human vs. Trained Agent\n",
        "def play_game():\n",
        "    current_board = initialize_board()\n",
        "    human_player = PLAYER_X\n",
        "\n",
        "    print(\"Welcome to Tic Tac Toe!\")\n",
        "    print(current_board)\n",
        "\n",
        "    train_q_learning()\n",
        "\n",
        "    while True:\n",
        "        if human_player == PLAYER_X:\n",
        "            row = int(input(\"Enter row (0, 1, or 2): \"))\n",
        "            col = int(input(\"Enter column (0, 1, or 2): \"))\n",
        "            action = (row, col)\n",
        "        else:\n",
        "            action = get_best_move(current_board, human_player)\n",
        "\n",
        "        if action in get_legal_moves(current_board):\n",
        "            make_move(current_board, human_player, *action)\n",
        "            print(current_board)\n",
        "\n",
        "            if check_winner(current_board):\n",
        "                print(\"You win!\")\n",
        "                break\n",
        "            elif np.all(current_board != EMPTY):\n",
        "                print(\"It's a draw!\")\n",
        "                break\n",
        "\n",
        "            # Switch player\n",
        "            human_player = PLAYER_O if human_player == PLAYER_X else PLAYER_X\n",
        "        else:\n",
        "            print(\"Invalid move. Try again.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    play_game()\n"
      ]
    }
  ]
}